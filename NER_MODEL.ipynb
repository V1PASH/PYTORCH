{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO5yci49suop1PoD/sKRWEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/V1PASH/PYTORCH/blob/main/NER_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D6cuLqlBz6R"
      },
      "outputs": [],
      "source": [
        "!pip install spacy tqdm datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "5idkPNFeCE9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "Fx6WO2qICKt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset =load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "CElc04yHCPsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "sc05B2f6CR0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=dataset[\"train\"]\n",
        "test_data=dataset[\"test\"]\n",
        "validation_data=dataset[\"validation\"]"
      ],
      "metadata": {
        "id": "zmLccKi5DCCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "Ht7EMx7CE9O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:3]"
      ],
      "metadata": {
        "id": "YaJgASyAFCBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.features[\"ner_tags\"].feature.names"
      ],
      "metadata": {
        "id": "TMgud8WeFJNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict={\n",
        "    \"O\":\"O\",\n",
        "    \"B-PER\":\"PER\",\n",
        "    \"I-PER\":\"PER\",\n",
        "    \"B-ORG\":\"ORG\",\n",
        "    \"I-ORG\":\"ORG\",\n",
        "    \"B-LOC\":\"GPE\",\n",
        "    \"I-LOC\":\"GPE\",\n",
        "    \"B-MISC\":\"MISC\",\n",
        "    \"I-MISC\":\"MISC\"\n",
        "}"
      ],
      "metadata": {
        "id": "D_gbWeeGFPD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict"
      ],
      "metadata": {
        "id": "Bu_YZAGkFnYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "bHULYzmUFsGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy link en_core_web_sm en\n"
      ],
      "metadata": {
        "id": "8nc979UmFuCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "OQGjU5DDF3m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc=nlp(\"Elon Musk Founded Tesla in America\")"
      ],
      "metadata": {
        "id": "HRvr86zzJXkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc.ents"
      ],
      "metadata": {
        "id": "dLJHKaFVJfyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_spacy(dataset_split):\n",
        "    output_data = []\n",
        "    for split in dataset_split:\n",
        "        words = split[\"tokens\"]\n",
        "        labels = split[\"ner_tags\"]\n",
        "        entities = []\n",
        "        text = \" \".join(words)\n",
        "        start = 0\n",
        "        for i, word in enumerate(words):\n",
        "            label = dataset[\"train\"].features[\"ner_tags\"].feature.int2str(labels[i])\n",
        "            label = label_dict.get(label, \"O\")\n",
        "\n",
        "            if label != \"O\":\n",
        "                entity_start = text.find(word, start)\n",
        "                entity_end = entity_start + len(word)\n",
        "                entities.append((entity_start, entity_end, label))\n",
        "                start = entity_end\n",
        "        output_data.append((text, {\"entities\": entities}))\n",
        "    return output_data\n"
      ],
      "metadata": {
        "id": "tYP5GbnGJgy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=convert_to_spacy(train_data)\n",
        "test_data=convert_to_spacy(test_data)\n",
        "validation_data=convert_to_spacy(validation_data)"
      ],
      "metadata": {
        "id": "J5AYliTSJr_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"train_data.json\", \"w\") as f:\n",
        "    json.dump(train_data, f)\n",
        "\n",
        "with open(\"validation_data.json\", \"w\") as f:\n",
        "    json.dump(validation_data, f)\n"
      ],
      "metadata": {
        "id": "RPvQMA_aNDDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[:3])"
      ],
      "metadata": {
        "id": "jZfpEZ9TJ3Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text, ann in train_data[:5]:\n",
        "    print(text, ann)"
      ],
      "metadata": {
        "id": "F0w0aqmrKDht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp=spacy.blank(\"en\")\n",
        "ner=nlp.add_pipe(\"ner\",last=True)"
      ],
      "metadata": {
        "id": "bC63zXGYKniz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, annotations in train_data:\n",
        "    for ent in annotations[\"entities\"]:\n",
        "        ner.add_label(ent[2])"
      ],
      "metadata": {
        "id": "mcZePPh0KNKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner.labels"
      ],
      "metadata": {
        "id": "-MGZwjAKKiQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp.pipe_names)"
      ],
      "metadata": {
        "id": "xhR7123kKvfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp.get_pipe(\"ner\").labels)"
      ],
      "metadata": {
        "id": "79dw_uEIK0jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.initialize()\n",
        "doc = nlp(\"Elon Musk founded SpaceX in 2002.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "id": "wUCH3xHdK68t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from spacy.training.example import Example\n",
        "\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.resume_training()\n",
        "    for itn in range(30):\n",
        "        random.shuffle(train_data)\n",
        "        losses = {}\n",
        "        for text, annotations in train_data:\n",
        "            doc = nlp.make_doc(text)\n",
        "            example = Example.from_dict(doc, annotations)\n",
        "            nlp.update([example], drop=0.3, losses=losses)\n",
        "        print(f\"epoch {itn+1}, Loss: {losses}\")"
      ],
      "metadata": {
        "id": "tIruVEJILDnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XqB7KtS3vw0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from spacy.training.example import Example\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "def evaluate_ner(nlp, examples):\n",
        "    scorer = Scorer()\n",
        "    example_objects = [Example.from_dict(nlp(text), annotations) for text, annotations in examples]\n",
        "    scores = scorer.score(example_objects)\n",
        "    precision = round(scores[\"ents_p\"] * 100, 2)\n",
        "    recall = round(scores[\"ents_r\"] * 100, 2)\n",
        "    f1_score = round(scores[\"ents_f\"] * 100, 2)\n",
        "    df = pd.DataFrame(\n",
        "        {\"Metric\": [\"Precision\", \"Recall\", \"F1-score\"], \"Score (%)\": [precision, recall, f1_score]}\n",
        "    )\n",
        "\n",
        "    return df\n",
        "results_df = evaluate_ner(nlp, test_data)\n",
        "\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "bnUaZ_BhxG2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "id": "Dv96WleZvwfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.to_disk(\"ner_model_n\")"
      ],
      "metadata": {
        "id": "lNZDEH4ZQBL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"ner_model_n\")"
      ],
      "metadata": {
        "id": "EMLs9TCmECbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Elon Musk founded SpaceX in 2002.\")\n",
        "print([(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "id": "t-ExWehbQDPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "\n",
        "text = \"Microsoft was founded by Bill Gates\"\n",
        "doc = nlp(text)\n",
        "\n",
        "displacy.render(doc,style=\"ent\",jupyter=True)\n"
      ],
      "metadata": {
        "id": "8DeVypFykNmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Microsoft was founded by Bill Gates and Apple was founded by Steve Jobs\"\n",
        "doc = nlp(text)\n",
        "\n",
        "displacy.render(doc,style=\"ent\",jupyter=True)"
      ],
      "metadata": {
        "id": "oqUrNcJPkvA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.training import Example\n",
        "from spacy.scorer import Scorer\n",
        "\n",
        "def evaluate_model(nlp, dataset):\n",
        "    scorer = Scorer()\n",
        "    examples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in dataset]\n",
        "    scores = scorer.score(examples)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "nNVNTlemk4-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from spacy.training.example import Example\n",
        "\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    optimizer = nlp.create_optimizer()\n",
        "    for itn in range(2):\n",
        "        random.shuffle(train_data)\n",
        "        losses = {}\n",
        "        for text, annotations in train_data:\n",
        "            doc = nlp.make_doc(text)\n",
        "            example = Example.from_dict(doc, annotations)\n",
        "            nlp.update([example], drop=0.3, losses=losses)\n",
        "        print(f\"epoch {itn+1}, Loss: {losses}\")"
      ],
      "metadata": {
        "id": "Y3TF-fqXlyrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "for text, annotations in test_data:\n",
        "    entity_labels = [\"O\"] * len(text.split())\n",
        "    for start, end, label in annotations[\"entities\"]:\n",
        "        word_idx = text[:start].count(\" \")\n",
        "        entity_labels[word_idx] = label\n",
        "    true_labels.append(entity_labels)"
      ],
      "metadata": {
        "id": "gQ2p2ZhulcIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_labels = []\n",
        "for text, _ in test_data:\n",
        "    doc = nlp(text)\n",
        "    entity_labels = [\"O\"] * len(text.split())\n",
        "    for ent in doc.ents:\n",
        "        word_idx = text[:ent.start_char].count(\" \")\n",
        "        entity_labels[word_idx] = ent.label_\n",
        "    pred_labels.append(entity_labels)\n"
      ],
      "metadata": {
        "id": "8hNKmmRElktb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "true_labels_flat = list(itertools.chain(*true_labels))\n",
        "pred_labels_flat = list(itertools.chain(*pred_labels))\n",
        "\n",
        "print(classification_report(true_labels_flat, pred_labels_flat))\n"
      ],
      "metadata": {
        "id": "9TZDhvfTEjU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Labels:\", set(itertools.chain(*true_labels)))\n",
        "print(\"Model Predictions:\", set(itertools.chain(*pred_labels)))\n"
      ],
      "metadata": {
        "id": "pXEoL23JHaBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "labels = list(set(true_labels_flat))\n",
        "\n",
        "cm = confusion_matrix(true_labels_flat, pred_labels_flat, labels=labels)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels, cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"NER Model Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qw5ZjkTsJxOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "entity_counts = collections.Counter(true_labels_flat)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(entity_counts.keys(), entity_counts.values(), color=\"skyblue\")\n",
        "plt.xlabel(\"Entity Type\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"Entity Distribution in Dataset\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "miZF9ytsTeHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "target_class = \"PERSON\"\n",
        "\n",
        "true_binary = [1 if label == target_class else 0 for label in true_labels_flat]\n",
        "pred_binary = [1 if label == target_class else 0 for label in pred_labels_flat]\n",
        "\n",
        "precision, recall, _ = precision_recall_curve(true_binary, pred_binary)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label=f'Precision-Recall Curve for {target_class}')\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(f\"Precision-Recall Curve for {target_class}\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oKf3q5HuTpYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRa3GfvrT5AF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}